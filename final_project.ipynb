{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb4b1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "folder_path = 'energydata'\n",
    "\n",
    "all_files = [f for f in os.listdir(folder_path) if f.endswith('_hourly.csv') and 'pjm' not in f.lower()]\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    region_name = file.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join(folder_path, file))\n",
    "    df['Region'] = region_name\n",
    "    df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "    df.rename(columns={df.columns[1]: 'Demand'}, inplace=True)\n",
    "    data_list.append(df)\n",
    "\n",
    "combined_data = pd.concat(data_list, ignore_index=True)\n",
    "combined_data.sort_values(by='Datetime', inplace=True)\n",
    "combined_data.to_csv('combined_regions_hourly.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c2db4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#randomly generated supply data but not in use \n",
    "np.random.seed(42)\n",
    "\n",
    "combined_data['WindSpeed'] = np.random.normal(5, 2, len(combined_data))\n",
    "combined_data['SolarRadiation'] = combined_data['Datetime'].dt.hour.apply(lambda x: 300 if 6 <= x <= 18 else 0)\n",
    "\n",
    "combined_data['SolarProduction'] = combined_data['SolarRadiation'] * 0.5\n",
    "combined_data['WindProduction'] = np.minimum(combined_data['WindSpeed'] * 2, 10)\n",
    "combined_data['FossilProduction'] = np.maximum(combined_data['Demand'] - \n",
    "                                               (combined_data['SolarProduction'] + combined_data['WindProduction']), 0)\n",
    "\n",
    "\n",
    "combined_data.to_csv('final_regions_with_simulation.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "33e190b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Datetime     Demand      Supply   Imbalance  Price  State\n",
      "0  2004-05-01 01:00:00   2.365480  193.082101  190.716621    100      5\n",
      "1  2004-05-01 02:00:00   0.346681 -463.712418 -464.059099    100      2\n",
      "2  2004-05-01 03:00:00  14.337037 -255.326996 -269.664032    100      3\n",
      "3  2004-05-01 04:00:00   0.000000 -877.417517 -877.417517    100      1\n",
      "4  2004-05-01 05:00:00  10.807845 -887.985104 -898.792948    100      1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# base on the demxand generated the supply data and design 30% change over supply\n",
    "overproduction_probability = 0.3\n",
    "adjustments = np.random.choice([-1, 1], size=len(data), p=[1 - overproduction_probability, overproduction_probability])\n",
    "\n",
    "# simulate the supply data\n",
    "data['Supply'] = data['Demand'] + adjustments * np.random.uniform(0, 1000, len(data))\n",
    "\n",
    "# add extra noise makes the simulation more natural\n",
    "data['Supply'] += np.random.normal(0, 100, len(data))\n",
    "\n",
    "#initialize price as 100\n",
    "data['Price'] = 100  \n",
    "\n",
    "# calculate the imbalance\n",
    "data['Imbalance'] = data['Supply'] - data['Demand']\n",
    "\n",
    "# define state\n",
    "imbalance_bins = np.linspace(data['Imbalance'].min(), data['Imbalance'].max(), 10)\n",
    "data['State'] = np.digitize(data['Imbalance'], imbalance_bins) - 1 \n",
    "\n",
    "data[['Datetime', 'Demand', 'Supply', 'Imbalance', 'Price', 'State']].to_csv('simulated_data.csv', index=False)\n",
    "\n",
    "print(data[['Datetime', 'Demand', 'Supply', 'Imbalance', 'Price', 'State']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8bff6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Total Reward = -45160\n",
      "Episode 2: Total Reward = -45330\n",
      "Episode 3: Total Reward = -41290\n",
      "Episode 4: Total Reward = -42960\n",
      "Episode 5: Total Reward = -43160\n",
      "Episode 6: Total Reward = -44040\n",
      "Episode 7: Total Reward = -40650\n",
      "Episode 8: Total Reward = -40990\n",
      "Episode 9: Total Reward = -42810\n",
      "Episode 10: Total Reward = -40690\n",
      "Episode 11: Total Reward = -42030\n",
      "Episode 12: Total Reward = -40190\n",
      "Episode 13: Total Reward = -40590\n",
      "Episode 14: Total Reward = -41400\n",
      "Episode 15: Total Reward = -41570\n",
      "Episode 16: Total Reward = -42800\n",
      "Episode 17: Total Reward = -43820\n",
      "Episode 18: Total Reward = -42040\n",
      "Episode 19: Total Reward = -46140\n",
      "Episode 20: Total Reward = -45100\n",
      "Episode 21: Total Reward = -45380\n",
      "Episode 22: Total Reward = -44080\n",
      "Episode 23: Total Reward = -42740\n",
      "Episode 24: Total Reward = -45600\n",
      "Episode 25: Total Reward = -43750\n",
      "Episode 26: Total Reward = -45270\n",
      "Episode 27: Total Reward = -42300\n",
      "Episode 28: Total Reward = -45130\n",
      "Episode 29: Total Reward = -43500\n",
      "Episode 30: Total Reward = -42600\n",
      "Episode 31: Total Reward = -42310\n",
      "Episode 32: Total Reward = -43220\n",
      "Episode 33: Total Reward = -44160\n",
      "Episode 34: Total Reward = -45150\n",
      "Episode 35: Total Reward = -43190\n",
      "Episode 36: Total Reward = -44020\n",
      "Episode 37: Total Reward = -42820\n",
      "Episode 38: Total Reward = -44440\n",
      "Episode 39: Total Reward = -41860\n",
      "Episode 40: Total Reward = -42710\n",
      "Episode 41: Total Reward = -43210\n",
      "Episode 42: Total Reward = -44050\n",
      "Episode 43: Total Reward = -43370\n",
      "Episode 44: Total Reward = -45230\n",
      "Episode 45: Total Reward = -44370\n",
      "Episode 46: Total Reward = -43000\n",
      "Episode 47: Total Reward = -45780\n",
      "Episode 48: Total Reward = -42550\n",
      "Episode 49: Total Reward = -41850\n",
      "Episode 50: Total Reward = -45370\n",
      "Episode 51: Total Reward = -42830\n",
      "Episode 52: Total Reward = -43470\n",
      "Episode 53: Total Reward = -44760\n",
      "Episode 54: Total Reward = -43870\n",
      "Episode 55: Total Reward = -42680\n",
      "Episode 56: Total Reward = -45280\n",
      "Episode 57: Total Reward = -42270\n",
      "Episode 58: Total Reward = -47860\n",
      "Episode 59: Total Reward = -42010\n",
      "Episode 60: Total Reward = -45290\n",
      "Episode 61: Total Reward = -43100\n",
      "Episode 62: Total Reward = -43320\n",
      "Episode 63: Total Reward = -43510\n",
      "Episode 64: Total Reward = -43540\n",
      "Episode 65: Total Reward = -45950\n",
      "Episode 66: Total Reward = -44800\n",
      "Episode 67: Total Reward = -45910\n",
      "Episode 68: Total Reward = -45220\n",
      "Episode 69: Total Reward = -44010\n",
      "Episode 70: Total Reward = -45540\n",
      "Episode 71: Total Reward = -47550\n",
      "Episode 72: Total Reward = -44100\n",
      "Episode 73: Total Reward = -44910\n",
      "Episode 74: Total Reward = -44860\n",
      "Episode 75: Total Reward = -44670\n",
      "Episode 76: Total Reward = -46860\n",
      "Episode 77: Total Reward = -49510\n",
      "Episode 78: Total Reward = -46210\n",
      "Episode 79: Total Reward = -45480\n",
      "Episode 80: Total Reward = -43510\n",
      "Episode 81: Total Reward = -45040\n",
      "Episode 82: Total Reward = -41480\n",
      "Episode 83: Total Reward = -46100\n",
      "Episode 84: Total Reward = -41820\n",
      "Episode 85: Total Reward = -42270\n",
      "Episode 86: Total Reward = -43550\n",
      "Episode 87: Total Reward = -43660\n",
      "Episode 88: Total Reward = -42540\n",
      "Episode 89: Total Reward = -44000\n",
      "Episode 90: Total Reward = -44950\n",
      "Episode 91: Total Reward = -44140\n",
      "Episode 92: Total Reward = -44690\n",
      "Episode 93: Total Reward = -44830\n",
      "Episode 94: Total Reward = -45430\n",
      "Episode 95: Total Reward = -44350\n",
      "Episode 96: Total Reward = -47080\n",
      "Episode 97: Total Reward = -44420\n",
      "Episode 98: Total Reward = -46710\n",
      "Episode 99: Total Reward = -44410\n",
      "Episode 100: Total Reward = -42490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# take a look for reward trend after learning\\nplt.plot(range(num_episodes), episode_rewards)\\nplt.title(\"Total Rewards Over Episodes\")\\nplt.xlabel(\"Episode\")\\nplt.ylabel(\"Total Reward\")\\nplt.show()\\n\\n# take a look at ele-price after learning\\nplt.plot(data[\\'Datetime\\'], data[\\'Price\\'])\\nplt.title(\"Electricity Price Over Time\")\\nplt.xlabel(\"Time\")\\nplt.ylabel(\"Price\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.iloc[:2000].reset_index(drop=True)\n",
    "def adjust_price_and_demand(row, action):\n",
    "    noise = np.random.normal(0, 5)  \n",
    "    if action == 0:  # Increase Price\n",
    "        new_price = row['Price'] * 1.1 + noise\n",
    "        new_demand = max(row['Demand'] * 0.9 - noise, 0)\n",
    "    elif action == 1:  # Decrease Price\n",
    "        new_price = row['Price'] * 0.9 + noise\n",
    "        new_demand = row['Demand'] * 1.1 + noise\n",
    "    else:  # Hold Price\n",
    "        new_price = row['Price']\n",
    "        new_demand = row['Demand']\n",
    "    return new_price, new_demand\n",
    "\n",
    "\n",
    "def calculate_reward_with_price(imbalance, fossil_production, price, action):\n",
    "    reward = 0\n",
    "\n",
    "    if abs(imbalance) < 200:  \n",
    "        reward += 100\n",
    "    if 80 <= price <= 150:\n",
    "        reward += 100\n",
    "    else:\n",
    "        reward -= 50\n",
    "    \n",
    "    if action == 0:  # Increase Price\n",
    "        reward += 50 if imbalance > 50 else -10\n",
    "    elif action == 1:  # Decrease Price\n",
    "        reward += 50 if imbalance < -50 else -10\n",
    "    elif action == 2:  # Hold Price\n",
    "        reward += 50 if abs(imbalance) < 50 else -10\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "#Q-Learning Agent\n",
    "class QLearningAgent:\n",
    "    def __init__(self, state_space, action_space, learning_rate=0.1, discount_factor=0.9, exploration_rate=0.2):\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.exploration_rate = exploration_rate  \n",
    "        self.q_table = np.zeros((state_space, action_space))  \n",
    "\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:  \n",
    "            return np.random.randint(self.action_space)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])  \n",
    "\n",
    "    def update_q_value(self, state, action, reward, next_state, done):\n",
    "        best_next_action = np.argmax(self.q_table[next_state]) \n",
    "        td_target = reward + self.discount_factor * self.q_table[next_state][best_next_action] * (1 - done)\n",
    "        td_error = td_target - self.q_table[state][action]  \n",
    "        self.q_table[state][action] += self.learning_rate * td_error \n",
    "\n",
    "state_space = len(imbalance_bins)  \n",
    "action_space = 3  \n",
    "agent = QLearningAgent(\n",
    "    state_space=state_space,\n",
    "    action_space=action_space,\n",
    "    learning_rate=0.1,\n",
    "    discount_factor=0.8, \n",
    "    exploration_rate=1.0  \n",
    ")\n",
    "\n",
    "num_episodes = 100\n",
    "episode_rewards = []  \n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    total_reward = 0\n",
    "\n",
    "    for idx in range(len(data) - 1):\n",
    "        current_row = data.iloc[idx]\n",
    "        next_row = data.iloc[idx + 1]\n",
    "        state = current_row['State']\n",
    "\n",
    "        action = agent.get_action(state)\n",
    "\n",
    "        new_price, new_demand = adjust_price_and_demand(current_row, action)\n",
    "        data.at[idx, 'Price'] = new_price  # update price each step\n",
    "        data.at[idx, 'Demand'] = new_demand  # update demand each step\n",
    "\n",
    "        adjusted_supply = current_row['Supply']\n",
    "        imbalance = adjusted_supply - new_demand\n",
    "\n",
    "        reward = calculate_reward_with_price(imbalance, current_row['FossilProduction'], new_price, action)\n",
    "\n",
    "        # get next state\n",
    "        next_state = next_row['State']\n",
    "        done = idx == len(data) - 2\n",
    "\n",
    "        # update Q table\n",
    "        agent.update_q_value(state, action, reward, next_state, done)\n",
    "        total_reward += reward\n",
    "\n",
    "    episode_rewards.append(total_reward)\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "    \n",
    "'''\n",
    "# take a look for reward trend after learning\n",
    "plt.plot(range(num_episodes), episode_rewards)\n",
    "plt.title(\"Total Rewards Over Episodes\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.show()\n",
    "\n",
    "# take a look at ele-price after learning\n",
    "plt.plot(data['Datetime'], data['Price'])\n",
    "plt.title(\"Electricity Price Over Time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd243c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be18d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
